{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ba4e49e-8066-4dd6-97fe-6238730bc8ac",
   "metadata": {},
   "source": [
    "This notebook is to understand the NAS pipeline and the differen \"modules/sections\" of the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bb0b6c0-5209-430b-b288-db55a693936f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f016978-c578-49c6-ae5c-e0e9b5e2f4e5",
   "metadata": {},
   "source": [
    "## 1. Search Space:\n",
    "\n",
    "The base model to explore is the same as in the original papers. The idea is to check the implementation for the `encoding/decoding` of the architectures and the `sampling` methodologies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8774c0da-c548-4ec0-8c1e-059675ab8e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.search_space import ofa\n",
    "\n",
    "space = ofa.OFASearchSpace('mobilenetv3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283459e3-9285-4cdd-b21e-518efae517dd",
   "metadata": {},
   "source": [
    "`Initialise` provides the initial set of architectures from which to start the search. The code shows that we are forcing the **inclusion of the minimal and maximal architectures**:\n",
    "\n",
    "```python\n",
    "def initialise(self, n_samples):\n",
    "    data = [self._get_min_sample(), self._get_max_sample()]\n",
    "    data.extend(self.sample(n_samples=(n_samples - 2)))\n",
    "    return data\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5723733e-e256-40eb-bf96-6e9f16a4e66f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'resolution': 192,\n",
       "  'depths': [2, 2, 2, 2, 2],\n",
       "  'ksizes': [3, 3, 3, 3, 3, 3, 3, 3, 3, 3],\n",
       "  'widths': [3, 3, 3, 3, 3, 3, 3, 3, 3, 3]},\n",
       " {'resolution': 256,\n",
       "  'depths': [4, 4, 4, 4, 4],\n",
       "  'ksizes': [7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7],\n",
       "  'widths': [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]},\n",
       " {'resolution': 220,\n",
       "  'depths': [3, 4, 4, 4, 4],\n",
       "  'ksizes': [3, 7, 3, 7, 5, 3, 3, 5, 3, 5, 3, 3, 7, 3, 7, 3, 5, 7, 7],\n",
       "  'widths': [3, 3, 3, 6, 3, 6, 6, 4, 3, 6, 6, 6, 3, 4, 4, 4, 6, 4, 3]}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = space.initialise(3)\n",
    "samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f6e953-7550-41e3-a85e-2b83d91785d4",
   "metadata": {},
   "source": [
    "The **encoding** and **decoding** of the architectures. This  is how the genetic algorithm sees the architectures and pools the descendants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40a1d70a-897b-452a-864b-07fc70d2bcd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3373033304753363664535343664373763444357746437'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding = space.encode( samples[2] )\n",
    "''.join( [str(a) for a in encoding ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6135a1d4-6a94-4474-81b6-64f180a27d48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'resolution': 220,\n",
       " 'depths': [3, 4, 4, 4, 4],\n",
       " 'ksizes': [3, 7, 3, 7, 5, 3, 3, 5, 3, 5, 3, 3, 7, 3, 7, 3, 5, 7, 7],\n",
       " 'widths': [3, 3, 3, 6, 3, 6, 6, 4, 3, 6, 6, 6, 3, 4, 4, 4, 6, 4, 3]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "space.decode(encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e6625c-1e2b-46a7-8860-6088198360c7",
   "metadata": {},
   "source": [
    "Now, just to perform a qualitative check, let's see if the `encoding -> decoding` works correctly for several random cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb79f0b6-2385-457b-bb72-3b08bc403dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = space.initialise(200)\n",
    "for sample in samples:\n",
    "    assert sample == space.decode(space.encode(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ed3d6e-0ebd-410e-a522-cf6c10fe17cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
