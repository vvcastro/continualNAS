{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be8b3227-f757-4e28-932a-5239f89823d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ofa.model_zoo as ofa\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "\n",
    "OFA_PATH = 'ofa_nets/ofa_mbv3_d234_e346_k357_w1.0'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2350bc8-b99e-43c6-bddd-dd3bc3f07f1a",
   "metadata": {},
   "source": [
    "Define a primitive to load the OFA net:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "301dd0d0-fbcf-49f6-a97b-eba8b9175a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_weights():\n",
    "    url_base = \"https://raw.githubusercontent.com/han-cai/files/master/ofa/ofa_nets/\"\n",
    "    gdown.download(url_base, OFA_PATH, quiet=False)\n",
    "\n",
    "def ofa_mobilenet( weights_path: str | None ):\n",
    "    \"\"\" Loads the MobileNetV3 model class and the corresponding weights \"\"\"\n",
    "    \n",
    "    network = ofa.OFAMobileNetV3(\n",
    "        dropout_rate=0,\n",
    "        width_mult=1.0,\n",
    "        ks_list=[3, 5, 7],\n",
    "        expand_ratio_list=[3, 4, 6],\n",
    "        depth_list=[2, 3, 4],\n",
    "    )\n",
    "\n",
    "    if not os.path.isfile(OFA_PATH):\n",
    "        download_weights()\n",
    "    init_weights = torch.load(OFA_PATH, map_location=\"cpu\")[\"state_dict\"]\n",
    "    network.load_state_dict(init_weights)\n",
    "    return network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa76409-5e83-45a6-8ee0-dad29ae1e757",
   "metadata": {},
   "source": [
    "## 1. Basic Class exploration:\n",
    "\n",
    "Load the OFA network and try to understand the different sampling strategies. Some checks:\n",
    "- **First Layer doesn't change** when changing archs.\n",
    "- **First Block doesn't change** when changing archs.\n",
    "- The rest of the **blocks (max: 20)** change depending on the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "530eabb3-4382-4a30-a219-c04be9ce3479",
   "metadata": {},
   "outputs": [],
   "source": [
    "ofa_network = ofa_mobilenet( OFA_PATH )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45940f29-af8d-45b2-9616-6e18e0e0b9e2",
   "metadata": {},
   "source": [
    "Check how the models change ( compare minimal vs maximal network ):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5d6b0be-7d8a-4c6c-847a-ea7e664725be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Blocks (MAX): 21\n",
      "Number of Blocks (MIN): 11\n"
     ]
    }
   ],
   "source": [
    "ofa_network.set_max_net()\n",
    "max_network = ofa_network.get_active_subnet(preserve_weight=True)\n",
    "print( \"Number of Blocks (MAX):\", len(max_network.blocks) )\n",
    "\n",
    "ofa_network.set_active_subnet(ks=3, e=3, d=2)\n",
    "min_network = ofa_network.get_active_subnet(preserve_weight=True)\n",
    "print( \"Number of Blocks (MIN):\", len(min_network.blocks) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45af561-d0d7-4cdf-bcd3-194b4abc9abd",
   "metadata": {},
   "source": [
    "Compare the blocks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc3038f1-411c-4d91-ac62-e58af48d248b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'ResidualBlock',\n",
       " 'conv': {'name': 'MBConvLayer',\n",
       "  'in_channels': 16,\n",
       "  'out_channels': 24,\n",
       "  'kernel_size': 3,\n",
       "  'stride': 2,\n",
       "  'expand_ratio': 3,\n",
       "  'mid_channels': 48,\n",
       "  'act_func': 'relu',\n",
       "  'use_se': False,\n",
       "  'groups': None},\n",
       " 'shortcut': None}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_network.config['blocks'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68b01a45-1315-45a6-b491-497339b5d2d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'ResidualBlock',\n",
       " 'conv': {'name': 'MBConvLayer',\n",
       "  'in_channels': 16,\n",
       "  'out_channels': 24,\n",
       "  'kernel_size': 7,\n",
       "  'stride': 2,\n",
       "  'expand_ratio': 6,\n",
       "  'mid_channels': 96,\n",
       "  'act_func': 'relu',\n",
       "  'use_se': False,\n",
       "  'groups': None},\n",
       " 'shortcut': None}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_network.config['blocks'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d202cf8-701b-4ef1-9671-a6b1d500fe0d",
   "metadata": {},
   "source": [
    "Check **how an \"expansion\" inside** the OFA could look.\n",
    "> Here we used a \"Wider\" transformation from one to the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7371496b-2185-4328-9c85-087438c26be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ofa_network.set_active_subnet(ks=3, e=[3, 3, 3, 3, 3], d=[1, 1, 1, 1, 1])\n",
    "base_network = ofa_network.get_active_subnet(preserve_weight=True)\n",
    "\n",
    "ofa_network.set_active_subnet(ks=3, e=[4, 3, 3, 3, 3], d=[1, 1, 1, 1, 1])\n",
    "expanded_network = ofa_network.get_active_subnet(preserve_weight=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4869b0-7991-4a3f-8b69-395aa97c416c",
   "metadata": {},
   "source": [
    "They differ (dimension-wise), only on the **block1**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70438723-2687-4dec-b65c-431932548983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(ResidualBlock(\n",
       "   (conv): MBConvLayer(\n",
       "     (inverted_bottleneck): Sequential(\n",
       "       (conv): Conv2d(16, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (act): ReLU(inplace=True)\n",
       "     )\n",
       "     (depth_conv): Sequential(\n",
       "       (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=48, bias=False)\n",
       "       (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (act): ReLU(inplace=True)\n",
       "     )\n",
       "     (point_linear): Sequential(\n",
       "       (conv): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " ResidualBlock(\n",
       "   (conv): MBConvLayer(\n",
       "     (inverted_bottleneck): Sequential(\n",
       "       (conv): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (act): ReLU(inplace=True)\n",
       "     )\n",
       "     (depth_conv): Sequential(\n",
       "       (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
       "       (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (act): ReLU(inplace=True)\n",
       "     )\n",
       "     (point_linear): Sequential(\n",
       "       (conv): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (bn): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       " ))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_network.blocks[1], expanded_network.blocks[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a110e63-46b3-4480-b9ee-f943445d6c79",
   "metadata": {},
   "source": [
    "Checking the weights on this block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c7d3ad4-4060-4866-92d6-063825e68d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (conv): Conv2d(16, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (act): ReLU(inplace=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "base_block = base_network.blocks[1]\n",
    "expanded_block = expanded_network.blocks[1]\n",
    "\n",
    "print( base_block.conv.inverted_bottleneck )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889c2268-f99a-4676-bdbd-b2165dc6ebd6",
   "metadata": {},
   "source": [
    "Starting with the first layer. We check the **shapes and the matching of these weights** values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e9df6430-dce6-4873-a9bb-b3414a9ae373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Layer: conv.inverted_bottleneck.conv.weight | Size: torch.Size([48, 16, 1, 1])\n",
      " - Expanded: conv.inverted_bottleneck.conv.weight | Size: torch.Size([64, 16, 1, 1])\n",
      " - Match?: tensor(True)\n",
      "\n",
      "Base Layer: conv.inverted_bottleneck.bn.weight | Size: torch.Size([48])\n",
      " - Expanded: conv.inverted_bottleneck.bn.weight | Size: torch.Size([64])\n",
      " - Match?: tensor(True)\n",
      "\n",
      "Base Layer: conv.inverted_bottleneck.bn.bias | Size: torch.Size([48])\n",
      " - Expanded: conv.inverted_bottleneck.bn.bias | Size: torch.Size([64])\n",
      " - Match?: tensor(True)\n",
      "\n",
      "Base Layer: conv.depth_conv.conv.weight | Size: torch.Size([48, 1, 3, 3])\n",
      " - Expanded: conv.depth_conv.conv.weight | Size: torch.Size([64, 1, 3, 3])\n",
      " - Match?: tensor(True)\n",
      "\n",
      "Base Layer: conv.depth_conv.bn.weight | Size: torch.Size([48])\n",
      " - Expanded: conv.depth_conv.bn.weight | Size: torch.Size([64])\n",
      " - Match?: tensor(True)\n",
      "\n",
      "Base Layer: conv.depth_conv.bn.bias | Size: torch.Size([48])\n",
      " - Expanded: conv.depth_conv.bn.bias | Size: torch.Size([64])\n",
      " - Match?: tensor(True)\n",
      "\n",
      "Base Layer: conv.point_linear.conv.weight | Size: torch.Size([24, 48, 1, 1])\n",
      " - Expanded: conv.point_linear.conv.weight | Size: torch.Size([24, 64, 1, 1])\n",
      " - Match?: tensor(True)\n",
      "\n",
      "Base Layer: conv.point_linear.bn.weight | Size: torch.Size([24])\n",
      " - Expanded: conv.point_linear.bn.weight | Size: torch.Size([24])\n",
      " - Match?: tensor(True)\n",
      "\n",
      "Base Layer: conv.point_linear.bn.bias | Size: torch.Size([24])\n",
      " - Expanded: conv.point_linear.bn.bias | Size: torch.Size([24])\n",
      " - Match?: tensor(True)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_layer = base_block\n",
    "expanded_layer = expanded_block\n",
    "\n",
    "for (bname, bparam), (ename, eparam) in zip( base_layer.named_parameters(), expanded_layer.named_parameters() ):\n",
    "    print( \"Base Layer:\", bname, \"| Size:\", bparam.shape)\n",
    "    # print(\" -\", bparam[:5, ...].reshape(-1) )\n",
    "\n",
    "    shared_axis = [ bparam.shape[i] != eparam.shape[i] for i in range( len(bparam.shape) ) ]\n",
    "    shared_axis = shared_axis.index(True) if True in shared_axis else 0\n",
    "        \n",
    "    if (shared_axis != 0):\n",
    "        shared_part = eparam[ :, :bparam.shape[shared_axis], ...]\n",
    "    else:\n",
    "        shared_part = eparam[ :bparam.shape[0], ...]\n",
    "        \n",
    "    \n",
    "    print( \" - Expanded:\", ename, \"| Size:\", eparam.shape)\n",
    "    print( \" - Match?:\", (shared_part == bparam).all() )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b9767c-bf27-44f3-a1cf-3854205bdd85",
   "metadata": {},
   "source": [
    "## 2. Understanding the model layers:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235059ba-5c7d-438d-a1e1-4b17a8032634",
   "metadata": {},
   "source": [
    "Interesting to understand all the \"types\" of blocks we have in the network.\n",
    "\n",
    "Basically, there a few blocks that are present with the same architecture in all the models:\n",
    "\n",
    "1. **First Conv:**\n",
    "\n",
    "```\n",
    "ConvLayer(\n",
    "  (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "  (act): Hswish()\n",
    ")\n",
    "```\n",
    "\n",
    "2. **Final Expand Layer:**\n",
    "\n",
    "```\n",
    "ConvLayer(\n",
    "  (conv): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "  (bn): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "  (act): Hswish() <CHECK>\n",
    ")\n",
    "```\n",
    "\n",
    "3. **Feature Mix Layer**:\n",
    "\n",
    "```\n",
    "ConvLayer(\n",
    "  (conv): Conv2d(960, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "  (act): Hswish()\n",
    ")\n",
    "```\n",
    "\n",
    "4. **Classifier:**\n",
    "\n",
    "```\n",
    "(classifier): LinearLayer(\n",
    "    (linear): Linear(in_features=1280, out_features=1000, bias=True)\n",
    "  )\n",
    "```\n",
    "\n",
    "Then, the intermediate layers `blocks` are basically constructs of `ResidualBlocks` with and without `shortcuts.` With a shape similar to:\n",
    "\n",
    "```\n",
    "ResidualBlock(\n",
    "    (conv): Sequential(...)\n",
    "    (shortcut): <optional>\n",
    ")\n",
    "```\n",
    "\n",
    "Here are the three main blocks for `conv`:\n",
    "\n",
    "1. **InvertedBottleNeck**: this one is optional and always goes at the beginning.\n",
    "```\n",
    "(inverted_bottleneck): Sequential(\n",
    "          (conv): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "          (act): ReLU(inplace=True)\n",
    "        )\n",
    "```\n",
    "\n",
    "2. **DepthConv**: is always there in a similar form, it may contain a last layer for `SqueezeExcitation`.\n",
    "```\n",
    "(depth_conv): Sequential(\n",
    "          (conv): Conv2d(144, 144, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=144, bias=False)\n",
    "          (bn): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "          (act): ReLU(inplace=True)\n",
    "          (se): SE(channel=144, reduction=4) <OPTIONAL>\n",
    "        )\n",
    "```\n",
    "\n",
    "4. **PointLinear**: Always included with the same architecture\n",
    "\n",
    "```\n",
    "(point_linear): Sequential(\n",
    "          (conv): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "          (bn): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        )\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "997b4203-262a-4e88-b6a7-69f7b044ecf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Hswish()\n"
     ]
    }
   ],
   "source": [
    "for name, child_mod in ( max_network.final_expand_layer.named_children() ):\n",
    "    # print(name)\n",
    "    print(child_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1ff44e86-a6cb-4a80-a29f-126d7edc6853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SE(channel=144, reduction=4)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_network.blocks[5].conv.depth_conv.se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bc1159-f623-43e8-97f6-55f07a58b091",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
